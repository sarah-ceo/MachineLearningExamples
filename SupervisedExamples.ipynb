{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import tensorflow as tf\n",
    "tf.autograph.set_verbosity(0)\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   passenger_id  850 non-null    int64  \n",
      " 1   pclass        850 non-null    int64  \n",
      " 2   name          850 non-null    object \n",
      " 3   sex           850 non-null    object \n",
      " 4   age           676 non-null    float64\n",
      " 5   sibsp         850 non-null    int64  \n",
      " 6   parch         850 non-null    int64  \n",
      " 7   ticket        850 non-null    object \n",
      " 8   fare          849 non-null    float64\n",
      " 9   cabin         191 non-null    object \n",
      " 10  embarked      849 non-null    object \n",
      " 11  boat          308 non-null    object \n",
      " 12  body          73 non-null     float64\n",
      " 13  home.dest     464 non-null    object \n",
      " 14  survived      850 non-null    int64  \n",
      "dtypes: float64(3), int64(5), object(7)\n",
      "memory usage: 99.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   passenger_id  pclass                                               name  \\\n0          1216       3                                 Smyth, Miss. Julia   \n1           699       3                                    Cacic, Mr. Luka   \n2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n4           576       2                                    Veal, Mr. James   \n\n      sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n0  female   NaN      0      0  335432   7.7333   NaN        Q   13   NaN   \n1    male  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n2  female  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n3  female  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n4    male  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n\n                  home.dest  survived  \n0                       NaN         1  \n1                   Croatia         0  \n2                       NaN         0  \n3      Cornwall / Akron, OH         1  \n4  Barre, Co Washington, VT         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>passenger_id</th>\n      <th>pclass</th>\n      <th>name</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>ticket</th>\n      <th>fare</th>\n      <th>cabin</th>\n      <th>embarked</th>\n      <th>boat</th>\n      <th>body</th>\n      <th>home.dest</th>\n      <th>survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1216</td>\n      <td>3</td>\n      <td>Smyth, Miss. Julia</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>0</td>\n      <td>335432</td>\n      <td>7.7333</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>13</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>699</td>\n      <td>3</td>\n      <td>Cacic, Mr. Luka</td>\n      <td>male</td>\n      <td>38.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>315089</td>\n      <td>8.6625</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Croatia</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1267</td>\n      <td>3</td>\n      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n      <td>female</td>\n      <td>30.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>345773</td>\n      <td>24.1500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>449</td>\n      <td>2</td>\n      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n      <td>female</td>\n      <td>54.0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>29105</td>\n      <td>23.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>Cornwall / Akron, OH</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>576</td>\n      <td>2</td>\n      <td>Veal, Mr. James</td>\n      <td>male</td>\n      <td>40.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>28221</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Barre, Co Washington, VT</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read Titanic training dataset\n",
    "df_train_all = pd.read_csv(\"./data/titanic_train.csv\")\n",
    "\n",
    "# Preview the data\n",
    "df_train_all.info()\n",
    "df_train_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0    537\n1    313\nName: survived, dtype: int64"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "      sex  survived\n0  female  0.702341\n1    male  0.186933",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sex</th>\n      <th>survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>female</td>\n      <td>0.702341</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>male</td>\n      <td>0.186933</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "   pclass  survived\n0       1  0.606796\n1       2  0.457831\n2       3  0.234310",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.606796</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.457831</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.234310</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some info about the data\n",
    "\n",
    "df_train_all[\"survived\"].value_counts()\n",
    "\n",
    "df_train_all[[\"sex\", \"survived\"]].groupby([\"sex\"], as_index=False).mean().sort_values(by=\"survived\", ascending=False)\n",
    "\n",
    "df_train_all[[\"pclass\", \"survived\"]].groupby([\"pclass\"], as_index=False).mean().sort_values(by=\"survived\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    # Drop some columns\n",
    "    columns = [\n",
    "        \"passenger_id\",\n",
    "        \"name\",\n",
    "        \"ticket\",\n",
    "        \"fare\",\n",
    "        \"cabin\",\n",
    "        \"embarked\", # Port of Embarkation (Cherbourg, Queenstown, Southampton)\n",
    "        \"boat\", # Lifeboat\n",
    "        \"body\", # Body Identification Number\n",
    "        \"home.dest\"] # Home / Destination\n",
    "    df = df.drop(columns, axis=1)\n",
    "\n",
    "    # Transform categorical data\n",
    "    df[\"sex\"] = LabelEncoder().fit_transform(df[\"sex\"])\n",
    "\n",
    "    # We could just drop the rows with NaN values, but we'd lose almost 200 examples\n",
    "    # df = df.dropna()\n",
    "\n",
    "    # Instead, we can impute the values, but fist we have to normalize the data\n",
    "    df = pd.DataFrame(MinMaxScaler().fit_transform(df), columns=df.columns)\n",
    "    df = pd.DataFrame(KNNImputer().fit_transform(df), columns=df.columns)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    850 non-null    float64\n",
      " 1   sex       850 non-null    float64\n",
      " 2   age       850 non-null    float64\n",
      " 3   sibsp     850 non-null    float64\n",
      " 4   parch     850 non-null    float64\n",
      " 5   survived  850 non-null    float64\n",
      "dtypes: float64(6)\n",
      "memory usage: 40.0 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   pclass  sex       age  sibsp     parch  survived\n0     1.0  0.0  0.331106  0.000  0.000000       1.0\n1     1.0  1.0  0.473904  0.000  0.000000       0.0\n2     1.0  0.0  0.373695  0.125  0.111111       0.0\n3     0.5  0.0  0.674321  0.125  0.333333       1.0\n4     0.5  1.0  0.498956  0.000  0.000000       0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.331106</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.473904</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.373695</td>\n      <td>0.125</td>\n      <td>0.111111</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>0.674321</td>\n      <td>0.125</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.498956</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples : X-> (637, 5) , Y-> (637,)\n",
      "Validation examples : X-> (213, 5) , Y-> (213,)\n"
     ]
    }
   ],
   "source": [
    "# Pre-process data\n",
    "df_train = preprocess_data(df_train_all)\n",
    "\n",
    "# Preview the data again\n",
    "df_train.info()\n",
    "df_train.head()\n",
    "\n",
    "# Separate our Xs and Ys\n",
    "X = df_train.drop([\"survived\"], axis=1).to_numpy()\n",
    "Y = np.squeeze(df_train[[\"survived\"]].to_numpy())\n",
    "\n",
    "# Split data into training and validation examples\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.25, random_state=42, stratify=Y)\n",
    "\n",
    "# Show our training and validation sizes\n",
    "print(\"Training examples : X->\", X_train.shape, \", Y->\", Y_train.shape)\n",
    "print(\"Validation examples : X->\", X_val.shape, \", Y->\", Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeClassifier(random_state=42)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  95.13\n",
      "Validation accuracy:  81.22\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, Y_train)\n",
    "print(\"Training accuracy: \", round(decision_tree.score(X_train, Y_train) * 100, 2))\n",
    "print(\"Validation accuracy: \", round(decision_tree.score(X_val, Y_val) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestClassifier(random_state=42)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  95.13\n",
      "Validation accuracy:  85.92\n"
     ]
    }
   ],
   "source": [
    "# Random forest\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "print(\"Training accuracy: \", round(random_forest.score(X_train, Y_train) * 100, 2))\n",
    "print(\"Validation accuracy: \", round(random_forest.score(X_val, Y_val) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Perceptron(random_state=42)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  77.86\n",
      "Validation accuracy:  76.53\n"
     ]
    }
   ],
   "source": [
    "# Perceptron\n",
    "perceptron = Perceptron(random_state=42)\n",
    "perceptron.fit(X_train, Y_train)\n",
    "print(\"Training accuracy: \", round(perceptron.score(X_train, Y_train) * 100, 2))\n",
    "print(\"Validation accuracy: \", round(perceptron.score(X_val, Y_val) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                384       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 8,769\n",
      "Trainable params: 8,769\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 1s 23ms/step - loss: 0.6566 - accuracy: 0.6201 - val_loss: 0.6271 - val_accuracy: 0.6338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.6016 - accuracy: 0.6311 - val_loss: 0.5906 - val_accuracy: 0.6338\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5683 - accuracy: 0.6672 - val_loss: 0.5641 - val_accuracy: 0.7324\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.5399 - accuracy: 0.7535 - val_loss: 0.5469 - val_accuracy: 0.7793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.5149 - accuracy: 0.7849 - val_loss: 0.5379 - val_accuracy: 0.7746\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4966 - accuracy: 0.7881 - val_loss: 0.5208 - val_accuracy: 0.7793\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4809 - accuracy: 0.7865 - val_loss: 0.5044 - val_accuracy: 0.8028\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4693 - accuracy: 0.7928 - val_loss: 0.4933 - val_accuracy: 0.7934\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4629 - accuracy: 0.7896 - val_loss: 0.4800 - val_accuracy: 0.8216\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4573 - accuracy: 0.7975 - val_loss: 0.4756 - val_accuracy: 0.8028\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4528 - accuracy: 0.8038 - val_loss: 0.4629 - val_accuracy: 0.8122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.4471 - accuracy: 0.7991 - val_loss: 0.4615 - val_accuracy: 0.8122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4454 - accuracy: 0.7896 - val_loss: 0.4534 - val_accuracy: 0.8169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4433 - accuracy: 0.7991 - val_loss: 0.4494 - val_accuracy: 0.8263\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4398 - accuracy: 0.8053 - val_loss: 0.4464 - val_accuracy: 0.8028\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4414 - accuracy: 0.8022 - val_loss: 0.4383 - val_accuracy: 0.8122\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4363 - accuracy: 0.7943 - val_loss: 0.4360 - val_accuracy: 0.7981\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.4370 - accuracy: 0.8100 - val_loss: 0.4319 - val_accuracy: 0.8169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 0.4331 - accuracy: 0.7991 - val_loss: 0.4293 - val_accuracy: 0.8075\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4317 - accuracy: 0.8006 - val_loss: 0.4287 - val_accuracy: 0.8169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x25cc7b7e460>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 3ms/step - loss: 0.4302 - accuracy: 0.8085\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Training accuracy:  80.85\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8169\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Validation accuracy:  81.69\n"
     ]
    }
   ],
   "source": [
    "# NN\n",
    "tf.random.set_seed(42)\n",
    "neural_network = tf.keras.models.Sequential()\n",
    "neural_network.add(tf.keras.layers.Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "neural_network.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "neural_network.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "neural_network.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "neural_network.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(neural_network.summary())\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
    "neural_network.fit(X_train, Y_train, epochs=20, batch_size=64, verbose=1, validation_data=(X_val, Y_val), callbacks=[early_stopping])\n",
    "print(\"Training accuracy: \", round(neural_network.evaluate(X_train, Y_train, batch_size=64)[1] * 100, 2))\n",
    "print(\"Validation accuracy: \", round(neural_network.evaluate(X_val, Y_val, batch_size=64)[1] * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 459 entries, 0 to 458\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   pclass  459 non-null    float64\n",
      " 1   sex     459 non-null    float64\n",
      " 2   age     459 non-null    float64\n",
      " 3   sibsp   459 non-null    float64\n",
      " 4   parch   459 non-null    float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 18.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "   pclass  sex       age  sibsp     parch\n0     0.0  1.0  0.235849  0.000  0.333333\n1     1.0  1.0  0.383019  0.000  0.000000\n2     0.0  1.0  0.433963  0.125  0.000000\n3     1.0  1.0  0.575472  0.000  0.000000\n4     1.0  1.0  0.292453  0.000  0.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pclass</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.235849</td>\n      <td>0.000</td>\n      <td>0.333333</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.383019</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.433963</td>\n      <td>0.125</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.575472</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.292453</td>\n      <td>0.000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read test_data\n",
    "df_test_all = pd.read_csv(\"./data/titanic_test.csv\")\n",
    "\n",
    "# Preprocess data\n",
    "df_test = preprocess_data(df_test_all)\n",
    "\n",
    "# Preview the test data\n",
    "df_test.info()\n",
    "df_test.head()\n",
    "\n",
    "# Convert to numpy array\n",
    "X_test = df_test.to_numpy()\n",
    "\n",
    "# Predict on test dataset and save results for Kaggle\n",
    "predictions = decision_tree.predict(X_test)\n",
    "df_predictions = pd.DataFrame({'passenger_id': df_test_all.passenger_id, \"survived\": predictions })\n",
    "df_predictions['survived'] = df_predictions['survived'].round(0).astype(int)\n",
    "df_predictions.to_csv(\"./outputs/decision_tree.csv\", index=False)\n",
    "\n",
    "predictions = random_forest.predict(X_test)\n",
    "df_predictions = pd.DataFrame({'passenger_id': df_test_all.passenger_id, \"survived\": predictions })\n",
    "df_predictions['survived'] = df_predictions['survived'].round(0).astype(int)\n",
    "df_predictions.to_csv(\"./outputs/random_forest.csv\", index=False)\n",
    "\n",
    "predictions = perceptron.predict(X_test)\n",
    "df_predictions = pd.DataFrame({'passenger_id': df_test_all.passenger_id, \"survived\": predictions })\n",
    "df_predictions['survived'] = df_predictions['survived'].round(0).astype(int)\n",
    "df_predictions.to_csv(\"./outputs/perceptron.csv\", index=False)\n",
    "\n",
    "predictions = np.squeeze(neural_network.predict(X_test))\n",
    "df_predictions = pd.DataFrame({'passenger_id': df_test_all.passenger_id, \"survived\": predictions })\n",
    "df_predictions['survived'] = df_predictions['survived'].round(0).astype(int)\n",
    "df_predictions.to_csv(\"./outputs/neural_network.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><h2>Accuracy results on test data according to Kaggle</h2></u>\n",
    "<hr/>\n",
    "<li>Decision Tree : <b>60.1%</b></li>\n",
    "<li>Random Forest : <b>82.6%</b></li>\n",
    "<li>Perceptron : <b>54.3%</b></li>\n",
    "<li>Neural Network : <b>90.5%</b></li>\n",
    "\n",
    "Simple example, can definitely improve by better selecting features, like in: https://anelmusic13.medium.com/how-to-score-top-3-in-kaggles-titanic-machine-learning-from-disaster-competition-13d056e262b1\n",
    "(split fare into categories, family size, cabin & ticket)\n",
    "\n",
    "Also, could definitely improve with parameters search and cross-validation.\n",
    "Decision Tree parameters : (criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0)\n",
    "Random Forest parameters : (n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)\n",
    "Perceptron parameters : (penalty=None, alpha=0.0001, l1_ratio=0.15, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)\n",
    "Neural Network parameter : () and hyper-parameters ()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}